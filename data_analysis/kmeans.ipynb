{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pandas_datareader as dr\n",
    "from math import sqrt\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our pipeline and define the classifier we plan to use for stocks within any of the 3 indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "preprocessor = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", MinMaxScaler())\n",
    "    ]\n",
    ")\n",
    "kmeans_kwargs = { \"init\": \"k-means++\", \"n_init\": 10, \"max_iter\": 300, \"random_state\": 42 }\n",
    "clf = Pipeline([\n",
    "    (\n",
    "        \"kmeans\",\n",
    "     KMeans(\n",
    "         **kmeans_kwargs\n",
    "     ),\n",
    "    ),\n",
    "])\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"clusterer\", clf)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sp500_url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "nasdaq100_url = 'https://en.wikipedia.org/wiki/Nasdaq-100'\n",
    "russell1000_url = 'https://en.wikipedia.org/wiki/Russell_1000_Index'\n",
    "indices = {\n",
    "    'sp500': {'index_url': sp500_url, 'table_num': 0, 'index_name': 'sp500'},\n",
    "    'nq100': {'index_url': nasdaq100_url, 'table_num': 3, 'index_name': 'nasdaq100'},\n",
    "    'rs1000': {'index_url': russell1000_url, 'table_num': 2, 'index_name': 'russell1000'}\n",
    "}\n",
    "engine = create_engine('sqlite:///indices_data', echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#read in the url and scrape ticker data\n",
    "def get_stocks_data(index_url, table_num, index_name):\n",
    "    \"\"\"\n",
    "    @param index_url: link to index (currently using Wikipedia)\n",
    "    @param table_num: table number on webpage since parsing HTML\n",
    "    @return: pd dataframe with close price data for all stocks in the index    \n",
    "    \"\"\"\n",
    "    # if we already have data no need to fetch, ret DF with pricing data for stocks in index \n",
    "    if index_name in set(engine.table_names()):\n",
    "        return pd.read_sql_table(table_name=index_name, con=engine, index_col='Date')\n",
    "    # otherwise, parse html, get prices for each ticker, etc.\n",
    "    data_table = pd.read_html(index_url)\n",
    "    # nq100 and rus1000 both have ticker in table instead of symbol.  \n",
    "    col_name = 'Symbol' if index_name == 'sp500' else 'Ticker'\n",
    "    tickers = data_table[table_num][col_name].values\n",
    "    prices_list = []\n",
    "    for idx, ticker in enumerate(tickers):\n",
    "        try:\n",
    "#             print(f\"Working with ticker...:{ticker} and {len(tickers) - idx} left to go.\")\n",
    "            # refactor (nothing really to change except merge/join v. concat)\n",
    "            prices = dr.DataReader(ticker,'yahoo','01/01/2017')['Adj Close']\n",
    "            ticker_prices = pd.DataFrame(prices)\n",
    "            ticker_prices.columns = [ticker]\n",
    "            prices_list.append(ticker_prices)\n",
    "        except:\n",
    "#             print(f\"Error with retrieving data for: {ticker}\")\n",
    "            pass\n",
    "        all_tickers_prices = pd.concat(prices_list, axis=1)\n",
    "#         print(f\"Added {ticker} to dataframe.\")\n",
    "    # sort alphabetically by ticker\n",
    "    all_tickers_prices.sort_index(inplace=True)\n",
    "    # cache prices in DB for future use\n",
    "    all_tickers_prices.to_sql(f'{index_name}', con=engine, if_exists='replace')\n",
    "    print(f'Finished {index_name}')\n",
    "    return all_tickers_prices\n",
    "\n",
    "\n",
    "#Calculate average annualized percentage return and volatilities over a theoretical one year period\n",
    "def calc_returns_vol(index_stock_prices, index_name):    \n",
    "    returns = index_stock_prices.pct_change().mean() * 252\n",
    "    volatility = index_stock_prices.pct_change().std() * sqrt(252)\n",
    "    ret_vol = pd.DataFrame({'Returns': returns, 'Volatility': volatility})\n",
    "    return ret_vol\n",
    "\n",
    "\n",
    "# fit Kmeans, get preprocessed data to use for plotting later. \n",
    "def kmeans_pipe_process(ret_vol):\n",
    "    pipe.fit(ret_vol[['Returns', 'Volatility']])\n",
    "    preprocessed_data = pipe['preprocessor'].transform(ret_vol[['Returns', 'Volatility']])\n",
    "#     print(f'silhouette score is {silhouette_score(preprocessed_data, predicted_labels)}')\n",
    "    # first col is normalized returns, second is volatility\n",
    "    scaled_ret_vol = pd.DataFrame({'Returns': preprocessed_data[:, 0], 'Volatility': preprocessed_data[:, 1]})\n",
    "#     print(scaled_ret_vol.head())\n",
    "    # can't return tuple since kmeans isn't iterable. \n",
    "    return {'kmeans': pipe['clusterer']['kmeans'], 'scaled': scaled_ret_vol}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# prices_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from kneed import KneeLocator\n",
    "\n",
    "def plot_elbow_curve(distortions):\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.plot(range(1, len(distortions) + 1), distortions)\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel(\"SSE\")\n",
    "    plt.title('Elbow curve')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def find_n_clusters(scaled_ret_vol, kmeans):\n",
    "    X = scaled_ret_vol[['Returns', 'Volatility']]\n",
    "    distortions = []\n",
    "    # 11 sectors in SP500, we are looking for optimal k for kmeans\n",
    "    for k in range(1, 12):\n",
    "        kmeans.n_clusters = k\n",
    "        kmeans.fit(X)\n",
    "        distortions.append(kmeans.inertia_)\n",
    "#         print(f\"Num clusters: {kmeans.n_clusters}\")\n",
    "    # display elbow curve\n",
    "    plot_elbow_curve(distortions)\n",
    "    kl = KneeLocator(range(1, len(distortions) + 1), distortions, S=1.0, curve=\"convex\", direction=\"decreasing\")\n",
    "    # kmeans_kwargs['n_clusters'] = kl.elbow\n",
    "    kmeans.n_clusters = kl.elbow\n",
    "#     print(f'num_clusters is: {kmeans.n_clusters}')\n",
    "    return kmeans.fit(scaled_ret_vol[['Returns', 'Volatility']])\n",
    "    \n",
    "    \n",
    "def disp_clusters_show_outliers(scaled_ret_vol, kmeans, index_name):\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "#     colors = ['red', 'blue', 'purple', 'yellow']\n",
    "    sns.scatterplot(x='Returns', y='Volatility', hue=kmeans.labels_, data=scaled_ret_vol, palette=\"deep\", s=100)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.title(f\"{index_name} Stocks Clustered into {kmeans.n_clusters} groups\")\n",
    "    centers = kmeans.cluster_centers_\n",
    "#     print(centers)\n",
    "    plt.scatter(centers[:, 0], centers[:, 1], c='black', s=400, alpha=0.5);\n",
    "    \n",
    "    \n",
    "def display_initial_results(scaled_ret_vol, kmeans, index_name):\n",
    "    find_n_clusters(scaled_ret_vol, kmeans)\n",
    "    disp_clusters_show_outliers(scaled_ret_vol, kmeans, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kmeans_all_indices(indices_data):\n",
    "    preprocessed_data_indices = {}\n",
    "    for index in indices_data:\n",
    "        index_ret_vol = calc_returns_vol(\n",
    "            # unpack args from dict into kwargs for get_stocks_data\n",
    "            index_stock_prices=get_stocks_data(**indices_data[index]), \n",
    "            index_name=indices[index]['index_name']\n",
    "        )\n",
    "#         print('before kmeans processing', index_ret_vol.head())\n",
    "        clf_preprocessed_data = kmeans_pipe_process(index_ret_vol)\n",
    "        preprocessed_data_indices[indices[index]['index_name']] = clf_preprocessed_data\n",
    "        kmeans_index, scaled_ret_vol = clf_preprocessed_data['kmeans'], clf_preprocessed_data['scaled']\n",
    "        display_initial_results(scaled_ret_vol, kmeans_index, indices_data[index]['index_name'])\n",
    "        \n",
    "    return preprocessed_data_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We see above from the plot that the \"elbow\" i.e., optimal number of clusters \"k\" is 4 but we can also find it programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# remove outliers from data set to get a more clear kmeans clustering\n",
    "def drop_outliers(ret_vol, ret_threshold, vol_threshold):\n",
    "    rm_outliers = ret_vol[(ret_vol['Returns'] < ret_threshold) & (ret_vol['Volatility'] < vol_threshold)]\n",
    "    return rm_outliers\n",
    "    # data = np.asarray([np.asarray(returns['Returns']),np.asarray(returns['Volatility'])]).T\n",
    "\n",
    "def plot_final_kmeans(index_name, kmeans, *args):\n",
    "    \"\"\"\n",
    "    @param index_name: name of stock index\n",
    "    @param kmeans: kmeans clf for index\n",
    "    @param *args: args to be passed to subsequent functions (df, returns/vol thresholds)\n",
    "    \"\"\"\n",
    "    # unpack variable args tuple needed for pos. args drop_outliers\n",
    "    returns_rm_outliers = drop_outliers(*args)\n",
    "    predicted_labels = find_n_clusters(returns_rm_outliers, kmeans).labels_\n",
    "#     predicted_labels = kmeans.fit(returns_rm_outliers[['Returns', 'Volatility']]).labels_\n",
    "    returns_rm_outliers['predicted_label'] = predicted_labels\n",
    "    centers = kmeans.cluster_centers_\n",
    "#     print(centers)\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "#     colors = ['red', 'blue', 'purple', 'green']\n",
    "    sns.scatterplot(x='Returns', y='Volatility', hue='predicted_label', data=returns_rm_outliers, palette='deep', s=100)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.title(f\"{index_name} Stocks Clustered into {kmeans.n_clusters} groups\")\n",
    "    plt.scatter(centers[:, 0], centers[:, 1], c='black', s=400, alpha=0.5);\n",
    "    plt.savefig(f\"C:\\\\Users\\\\joshu\\\\PycharmProjects\\\\finance-project\\\\website\\\\static\\\\images\\\\{index_name}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, we plot the data after running KMeans with the outliers removed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "prepr_data_indices = run_kmeans_all_indices(indices)\n",
    "# print(prepr_data_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the charts above, we see the outliers for each index after preprocessing are in the range of: \n",
    "- S&P500: Returns $\\geq$ 0.40 and Volatility $\\geq$ 0.6 \n",
    "- Nasdaq 100: Returns $\\geq$ 0.6 and Volatility $\\geq$ 0.6\n",
    "- Russell 1000: Returns $\\geq$ 0.2 and Volatility $\\geq$ 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting final elbow charts with new number of clusters and filtered data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepr_data_indices['sp500']['ret_threshold'], prepr_data_indices['sp500']['vol_threshold'] = 0.4, 0.6\n",
    "prepr_data_indices['nasdaq100']['ret_threshold'], prepr_data_indices['nasdaq100']['vol_threshold'] = 0.6, 0.6\n",
    "prepr_data_indices['russell1000']['ret_threshold'], prepr_data_indices['russell1000']['vol_threshold'] = 0.2, 0.1\n",
    "for index in prepr_data_indices:\n",
    "    outliers_dropped = plot_final_kmeans(index, prepr_data_indices[index]['kmeans'], prepr_data_indices[index]['scaled'], prepr_data_indices[index]['ret_threshold'], prepr_data_indices[index]['vol_threshold'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}